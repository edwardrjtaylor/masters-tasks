{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import feature\n",
    "import scipy\n",
    "from scipy.stats import chisquare\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "from scipy.optimize import least_squares\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "import os\n",
    "from scipy import signal\n",
    "import time\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from skimage.transform import hough_line, hough_line_peaks\n",
    "from skimage.feature import canny\n",
    "from matplotlib import cm\n",
    "import argparse\n",
    "\n",
    "folder = 'Calib_10days/'\n",
    "filename = 'Calibration_10days_'\n",
    "filepath = folder+filename\n",
    "filetype = '.tiff'\n",
    "\n",
    "#filename = 'Distance_Simulation/'\n",
    "params = {'legend.fontsize': '22',\n",
    "          'figure.figsize': (10, 8),\n",
    "         'axes.labelsize': '22',\n",
    "         'axes.titlesize':'22',\n",
    "         'xtick.labelsize':'22',\n",
    "         'ytick.labelsize':'22'}\n",
    "\n",
    "\n",
    "def getImageDescription(im): return ast.literal_eval(im.tag[270][0])\n",
    "def getClockScalingFactor(): return (28/1000)/(1750000) \n",
    "def get_tiff_integration_time(im): return float(getImageDescription(im)[\"integration time\"])*getClockScalingFactor()\n",
    "\n",
    "\n",
    "#Going to use this to get rid of dodgy files with 0 integration time\n",
    "#Courtesy of sam\n",
    "\n",
    "def get_file_nums(folder): #function returns ordered list of numbers of files in folder\n",
    "    _, dirs, files = next(os.walk(folder))\n",
    "    nums = ([])\n",
    "    for file in files:\n",
    "        try: \n",
    "            nums.append(int(file.replace(filename, '').replace(filetype, '')))\n",
    "        except: continue\n",
    "    return sorted(nums)\n",
    "\n",
    "\n",
    "def snip(image,chop=2): return np.array([l[chop:-chop-1] for l in image[chop:-chop-1]])\n",
    "    #This chops L R U D chop number of elements (so Hough works)\n",
    "\n",
    "def image_ret(file_num, col=0):\n",
    "    full_img = tiff.imread(filepath+str(file_num)+'.tiff')[:,:,col]\n",
    "    #am inverting and changing mm.tiff \n",
    "    #full_img = np.invert(full_img)\n",
    "    return snip(full_img)\n",
    "\n",
    "\n",
    "def line_eqn(line): \n",
    "    x0,x1,y0,y1 = line\n",
    "    m = (y1-y0)/(x1-x0)\n",
    "    c = y0\n",
    "    return [m,c]\n",
    "\n",
    "def find_intercept(line1, line2):\n",
    "    m1,c1 = line1\n",
    "    m2,c2 = line2\n",
    "    x = (c1-c2) / (m2-m1)\n",
    "    y = m1 * x + c1\n",
    "    return [x,y]  \n",
    "\n",
    "def cross_points(image,lines):\n",
    "    #takes lines and works out where they cross \n",
    "    #returns list of [x1,y1], [x2,y2]... of where points are\n",
    "    done_list =([])\n",
    "    pts = ([])\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(len(lines)):\n",
    "            if i!=j and not any(point in done_list for point in [[i, j], [j, i]]):\n",
    "                done_list.append([i,j])\n",
    "                p1,p2 = find_intercept(lines[i],lines[j])\n",
    "                if 0<p1<image.shape[0] and 0<p2<image.shape[1]:\n",
    "                    pts.append([int(p1),int(p2)])\n",
    "    return pts\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    sqr = np.zeros((4, 2), dtype = \"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    sqr[0] = pts[np.argmin(s)]\n",
    "    sqr[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    sqr[1] = pts[np.argmin(diff)]\n",
    "    sqr[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return sqr\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    # height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    #specifying points\n",
    "    # top-left, top-right, bottom-right, and bottom-left\n",
    "    sqr = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "        # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, sqr)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    # return the warped image\n",
    "    return warped\n",
    "\n",
    "def sum_pixel(images): return images.sum(axis=0)\n",
    "def avg_pv(numbers): return np.array([image_ret(i) for i in bckr_count]).mean(axis=0)\n",
    "\n",
    "dark_img_folder = 'Define this folder'\n",
    "bckgr_count = get_file_nums(dark_img_folder)\n",
    "#assumes the filename is the same as for normal files\n",
    "dark = avg_pv(bckgr_count)\n",
    "\n",
    "\n",
    "print(get_file_nums(folder))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import files\n",
    "    #define image locations\n",
    "    #define dark locations\n",
    "#got to define threshold for mean of image when it is below a certain value\n",
    "    #use average of pixel value for whole image\n",
    "#use greater than threshold - not background\n",
    "#minus dark from images to get irradiation\n",
    "#irrad_images - dark\n",
    "\n",
    "#didn't move LASSENA so should be same pts for all images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
